{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 開倉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leveage:  0.2\n",
      "guarantee_money:  10.0\n"
     ]
    }
   ],
   "source": [
    "exp_lose_money = 50\n",
    "exp_lose_ratio = 0.5\n",
    "maintain_ratio = 0.1\n",
    "\n",
    "leveage = maintain_ratio / exp_lose_ratio\n",
    "guarantee_money = exp_lose_money * leveage\n",
    "\n",
    "print(\"leveage: \", leveage)\n",
    "print(\"guarantee_money: \", guarantee_money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "timezone = pytz.timezone('Asia/Taipei')\n",
    "\n",
    "start_time = timezone.localize(datetime(2024, 8, 20)).astimezone(pytz.UTC)\n",
    "end_time = timezone.localize(datetime(2024, 8, 21)).astimezone(pytz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcryptoprice(symbol, start_time, end_time, interval, limit):\n",
    "    \n",
    "    base_url = 'https://fapi.binance.com'\n",
    "    symbol = symbol\n",
    "    limit = limit\n",
    "    interval = interval\n",
    "    \n",
    "    # Convert datetime to timestamp in milliseconds\n",
    "    def timestamp_to_int(dt):\n",
    "        return int(datetime.timestamp(dt) * 1000)\n",
    "    \n",
    "    start_time = timestamp_to_int(start_time)\n",
    "    end_time = timestamp_to_int(end_time)\n",
    "\n",
    "    # Convert UTC timestamp to Asia/Taipei timezone\n",
    "    def convert_to_taipei_time(utc_timestamp):\n",
    "        return datetime.fromtimestamp(utc_timestamp / 1000, pytz.timezone('Asia/Taipei'))\n",
    "\n",
    "    def get_historical_klines(df, start_time):\n",
    "        endpoint = '/fapi/v1/klines'\n",
    "        Interval = interval\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'interval': Interval,\n",
    "            'startTime': start_time,\n",
    "            #'endTime': start_time + limit * 60 * 1000 - 1,\n",
    "            'limit': 400\n",
    "        }\n",
    "        url = base_url + endpoint\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            klines_df = pd.DataFrame(data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'])\n",
    "            \n",
    "            # Convert timestamp to Asia/Taipei timezone\n",
    "            klines_df['timestamp'] = klines_df['timestamp'].apply(convert_to_taipei_time)\n",
    "            \n",
    "            df = pd.concat([df, klines_df], ignore_index=True)\n",
    "            #print(f'Symbol: {symbol}, Fetched {len(klines_df)} klines from {klines_df[\"timestamp\"].min()} to {klines_df[\"timestamp\"].max()} (Asia/Taipei)')\n",
    "        else:\n",
    "            print(f'Error: {response.status_code}')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Fetch data in loop\n",
    "    while start_time < end_time:\n",
    "        df = get_historical_klines(df, start_time)\n",
    "        start_time += 5 * 60 * 1000\n",
    "        \n",
    "    return df\n",
    "\n",
    "def getcryptoOI(symbol, start_time, end_time, interval, limit):\n",
    "    \n",
    "    base_url = 'https://fapi.binance.com'\n",
    "    symbol = symbol\n",
    "    limit = limit\n",
    "    period = interval\n",
    "    \n",
    "    # Convert datetime to timestamp in milliseconds\n",
    "    def timestamp_to_int(dt):\n",
    "        return int(datetime.timestamp(dt) * 1000)\n",
    "    \n",
    "    start_time = timestamp_to_int(start_time)\n",
    "    end_time = timestamp_to_int(end_time)\n",
    "\n",
    "    # Convert UTC timestamp to Asia/Taipei timezone\n",
    "    def convert_to_taipei_time(utc_timestamp):\n",
    "        return datetime.fromtimestamp(utc_timestamp / 1000, pytz.timezone('Asia/Taipei'))\n",
    "\n",
    "    # Function to get historical OI and append to DataFrame\n",
    "    def get_historical_OI(df, start_time):\n",
    "        endpoint = '/futures/data/openInterestHist'\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'period': period,\n",
    "            'startTime': start_time,\n",
    "            #'endTime': start_time + limit * 60 * 1000 - 1,\n",
    "            'limit': 400\n",
    "        }\n",
    "        url = base_url + endpoint\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            OI_df = pd.DataFrame(data, columns=['timestamp', 'sumOpenInterest', 'sumOpenInterestValue'])\n",
    "            OI_df['timestamp'] = OI_df['timestamp'].apply(convert_to_taipei_time)\n",
    "            df = pd.concat([df, OI_df], ignore_index=True)\n",
    "            #print(f'Symbol: {symbol}, Fetched {len(OI_df)} OI from {OI_df[\"timestamp\"].min()} to {OI_df[\"timestamp\"].max()}')\n",
    "        else:\n",
    "            print(f'Error: {response.status_code}')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Fetch data in loop\n",
    "    while start_time < end_time:\n",
    "        df = get_historical_OI(df, start_time)\n",
    "        start_time += 5 * 60 * 1000  # Move to next 15 minutes\n",
    "\n",
    "    return df\n",
    "\n",
    "def getcryptoOIlongshort(symbol, start_time, end_time, interval, limit):\n",
    "    \n",
    "    base_url = 'https://fapi.binance.com'\n",
    "    symbol = symbol\n",
    "    limit = limit\n",
    "    period = interval\n",
    "    \n",
    "    # Convert datetime to timestamp in milliseconds\n",
    "    def timestamp_to_int(dt):\n",
    "        return int(datetime.timestamp(dt) * 1000)\n",
    "    \n",
    "    start_time = timestamp_to_int(start_time)\n",
    "    end_time = timestamp_to_int(end_time)\n",
    "\n",
    "    # Convert UTC timestamp to Asia/Taipei timezone\n",
    "    def convert_to_taipei_time(utc_timestamp):\n",
    "        return datetime.fromtimestamp(utc_timestamp / 1000, pytz.timezone('Asia/Taipei'))\\\n",
    "    \n",
    "    # Function to get historical OI and append to DataFrame\n",
    "    def get_historical_longshort(df, start_time):\n",
    "        endpoint = '/futures/data/globalLongShortAccountRatio'\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'period': period,\n",
    "            'startTime': start_time,\n",
    "            #'endTime': start_time + limit * 60 * 1000 - 1,\n",
    "            'limit': 400\n",
    "        }\n",
    "        url = base_url + endpoint\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            longshort_df = pd.DataFrame(data, columns=['timestamp', 'longShortRatio', 'longaccount', 'shortaccount'])\n",
    "            longshort_df['timestamp'] = longshort_df['timestamp'].apply(convert_to_taipei_time)\n",
    "            df = pd.concat([df, longshort_df], ignore_index=True)\n",
    "            #print(f'Symbol: {symbol}, Fetched {len(longshort_df)} longshort from {longshort_df[\"timestamp\"].min()} to {longshort_df[\"timestamp\"].max()}')\n",
    "        else:\n",
    "            print(f'Error: {response.status_code}')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Fetch data in loop\n",
    "    while start_time < end_time:\n",
    "        df = get_historical_longshort(df, start_time)\n",
    "        start_time += 5 * 60 * 1000  # Move to next 15 minutes\n",
    "\n",
    "    return df\n",
    "\n",
    "def getsignal(symbol, start_time, end_time, interval, limit):\n",
    "    df = getcryptoprice(symbol, start_time, end_time, interval, limit)\n",
    "    df_OI = getcryptoOI(symbol, start_time, end_time, interval, limit)\n",
    "    df_longshort = getcryptoOIlongshort(symbol, start_time, end_time, interval, limit)\n",
    "    \n",
    "    df = pd.merge(df, df_OI, on='timestamp', how='left')\n",
    "    df = pd.merge(df, df_longshort, on='timestamp', how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 39.1 GiB for an array with shape (5243439888,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m signal \u001b[38;5;241m=\u001b[39m \u001b[43mgetsignal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAVEUSDT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[82], line 163\u001b[0m, in \u001b[0;36mgetsignal\u001b[1;34m(symbol, start_time, end_time, interval, limit)\u001b[0m\n\u001b[0;32m    160\u001b[0m df_longshort \u001b[38;5;241m=\u001b[39m getcryptoOIlongshort(symbol, start_time, end_time, interval, limit)\n\u001b[0;32m    162\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df, df_OI, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 163\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_longshort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1151\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1759\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     _, lidx, ridx \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mjoin(right, how\u001b[38;5;241m=\u001b[39mhow, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1759\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mget_join_indexers_non_unique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(lidx, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m   1764\u001b[0m     lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\quant\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1795\u001b[0m, in \u001b[0;36mget_join_indexers_non_unique\u001b[1;34m(left, right, sort, how)\u001b[0m\n\u001b[0;32m   1793\u001b[0m lkey, rkey, count \u001b[38;5;241m=\u001b[39m _factorize_keys(left, right, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1795\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mlibjoin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_outer_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1797\u001b[0m     ridx, lidx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join(rkey, lkey, count, sort\u001b[38;5;241m=\u001b[39msort)\n",
      "File \u001b[1;32mjoin.pyx:116\u001b[0m, in \u001b[0;36mpandas._libs.join.left_outer_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 39.1 GiB for an array with shape (5243439888,) and data type int64"
     ]
    }
   ],
   "source": [
    "signal = getsignal('AAVEUSDT',start_time,end_time,'5m',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take_profit:  0.039643899999999996\n",
      "stop_loss:  0.041278699999999995\n"
     ]
    }
   ],
   "source": [
    "order_price = 0.04087\n",
    "earn_ratio = 0.03\n",
    "lost_ratio = 0.01\n",
    "\n",
    "take_profit = order_price * (1-earn_ratio)\n",
    "stop_loss = order_price * (1+lost_ratio)\n",
    "print(\"take_profit: \", take_profit)\n",
    "print(\"stop_loss: \", stop_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take_profit:  0.725635\n",
      "stop_loss:  0.67632\n"
     ]
    }
   ],
   "source": [
    "order_price = 0.7045\n",
    "earn_ratio = 0.03\n",
    "lost_ratio = 0.04\n",
    "\n",
    "take_profit = order_price * (1+earn_ratio)\n",
    "stop_loss = order_price * (1-lost_ratio)\n",
    "print(\"take_profit: \", take_profit)\n",
    "print(\"stop_loss: \", stop_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
